{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4925c228-5077-400b-9c3e-68f5c9ace1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from typing import List\n",
    "from wan.modules.vae import WanVAE\n",
    "\n",
    "def tensors_to_mp4_rgb(tensor_list: List[torch.Tensor], output_path: str, fps: int = 30):\n",
    "    \"\"\"Convert a list of PyTorch tensors to an MP4 video file with H.264 codec.\"\"\"\n",
    "    if not tensor_list:\n",
    "        raise ValueError(\"tensor_list is empty\")\n",
    "    \n",
    "    height, width = 480, 832\n",
    "    \n",
    "    # First, write to a temporary file with a codec that OpenCV supports\n",
    "    temp_path = output_path.replace('.mp4', '_temp.mp4')\n",
    "    \n",
    "    # Try different codecs in order of preference\n",
    "    codecs_to_try = [\n",
    "        cv2.VideoWriter_fourcc(*'avc1'),  # H.264 variant\n",
    "        cv2.VideoWriter_fourcc(*'H264'),  # H.264\n",
    "        cv2.VideoWriter_fourcc(*'mp4v'),  # MPEG-4\n",
    "        cv2.VideoWriter_fourcc(*'XVID'),  # XVID\n",
    "    ]\n",
    "    \n",
    "    out = None\n",
    "    for fourcc in codecs_to_try:\n",
    "        out = cv2.VideoWriter(temp_path, fourcc, fps, (width, height), isColor=True)\n",
    "        if out.isOpened():\n",
    "            print(f\"Using codec: {fourcc}\")\n",
    "            break\n",
    "    \n",
    "    if not out or not out.isOpened():\n",
    "        raise ValueError(\"Failed to open video writer with any codec\")\n",
    "    \n",
    "    for tensor in tensor_list:\n",
    "        # Handle both [3, 832, 480] and [3, 1, 832, 480] shapes\n",
    "        if tensor.dim() == 4:\n",
    "            frame = tensor.squeeze(1)\n",
    "        else:\n",
    "            frame = tensor\n",
    "            \n",
    "        # Convert from CHW to HWC format\n",
    "        frame = frame.permute(1, 2, 0)\n",
    "        frame_np = frame.cpu().numpy()\n",
    "        \n",
    "        # Normalize to 0-255 range\n",
    "        if frame_np.max() <= 1.0:\n",
    "            frame_np = (frame_np * 255).astype(np.uint8)\n",
    "        else:\n",
    "            frame_np = frame_np.astype(np.uint8)\n",
    "        \n",
    "        # Convert RGB to BGR for OpenCV\n",
    "        frame_bgr = cv2.cvtColor(frame_np, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame_bgr)\n",
    "    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Convert using ffmpeg if available (best compatibility)\n",
    "    try:\n",
    "        import subprocess\n",
    "        # Use ffmpeg to convert to a universally compatible H.264 MP4\n",
    "        cmd = [\n",
    "            'ffmpeg', '-y', '-i', temp_path,\n",
    "            '-c:v', 'libx264',  # H.264 codec\n",
    "            '-pix_fmt', 'yuv420p',  # Pixel format for compatibility\n",
    "            '-movflags', '+faststart',  # For web playback\n",
    "            output_path\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True, capture_output=True)\n",
    "        os.remove(temp_path)\n",
    "        print(f\"Video saved with H.264 codec to: {output_path}\")\n",
    "    except:\n",
    "        # If ffmpeg is not available, just rename the temp file\n",
    "        if os.path.exists(temp_path):\n",
    "            os.rename(temp_path, output_path)\n",
    "        print(f\"Video saved to: {output_path} (without ffmpeg conversion)\")\n",
    "\n",
    "# def tensors_to_mp4_rgb(tensor_list: List[torch.Tensor], output_path: str, fps: int = 16):\n",
    "#     \"\"\"Convert a list of PyTorch tensors to an MP4 video file (RGB).\"\"\"\n",
    "#     if not tensor_list:\n",
    "#         raise ValueError(\"tensor_list is empty\")\n",
    "    \n",
    "#     height, width = 832, 480\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter(output_path, fourcc, fps, (width, height), isColor=True)\n",
    "    \n",
    "#     for tensor in tensor_list:\n",
    "#         # Handle both [3, 832, 480] and [3, 1, 832, 480] shapes\n",
    "#         if tensor.dim() == 4:\n",
    "#             frame = tensor.squeeze(1)\n",
    "#         else:\n",
    "#             frame = tensor\n",
    "            \n",
    "#         # Convert from CHW to HWC format\n",
    "#         frame = frame.permute(1, 2, 0)\n",
    "#         frame_np = frame.cpu().numpy()\n",
    "        \n",
    "#         # Normalize to 0-255 range\n",
    "#         if frame_np.max() <= 1.0:\n",
    "#             frame_np = (frame_np * 255).astype(np.uint8)\n",
    "#         else:\n",
    "#             frame_np = frame_np.astype(np.uint8)\n",
    "        \n",
    "#         # Convert RGB to BGR for OpenCV\n",
    "#         frame_bgr = cv2.cvtColor(frame_np, cv2.COLOR_RGB2BGR)\n",
    "#         out.write(frame_bgr)\n",
    "    \n",
    "#     out.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     print(f\"Video saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985e8d0c-ef98-44e3-b4be-52fb403df10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 21, 60, 104])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_orig = torch.load('latent_pre_patch.pt')\n",
    "latent_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6002ee81-aace-4af2-bf42-0f7596a025e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_orig shape: torch.Size([20, 21, 60, 104]), t_comfy shape: torch.Size([20, 21, 60, 104])\n"
     ]
    }
   ],
   "source": [
    "# Setup device and VAE\n",
    "device = torch.device(\"cuda:0\")\n",
    "vae = WanVAE(\n",
    "    vae_pth=os.path.join('/workspace/', 'wan_2.1_vae.safetensors'),\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Load tensors\n",
    "t_orig = torch.load('vae_latent.pt')\n",
    "t_comfy = torch.load('/ComfyUI_fork/res.pt')\n",
    "\n",
    "if t_orig.dim() == 5:\n",
    "    t_orig = t_orig.squeeze(0)\n",
    "if t_comfy.dim() == 5:\n",
    "    t_comfy = t_comfy.squeeze(0)\n",
    "\n",
    "# Compare tensors\n",
    "print(f\"t_orig shape: {t_orig.shape}, t_comfy shape: {t_comfy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2b8c69-2fd9-48ea-9958-87c1f8c629e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference - min: -0.0406, max: 0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ATI/wan_ati_standalone/wan/modules/vae.py:662: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(dtype=self.dtype):\n"
     ]
    }
   ],
   "source": [
    "print(f\"Difference - min: {(t_orig - t_comfy).min():.4f}, max: {(t_orig - t_comfy).max():.4f}\")\n",
    "# Decode latents (skip first 4 channels if needed)\n",
    "# Note: Based on your history, you're using indices [4:] to skip some channels\n",
    "d_orig = vae.decode([t_orig[4:]])[0]\n",
    "d_comfy = vae.decode([t_comfy[4:]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a948cfe-db23-4a31-ac25-2e23aae0439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_orig - t_comfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b803a35f-7f4d-49b3-9f63-e85576f8a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(135106.1562, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "diff = d_orig - d_comfy\n",
    "print(diff.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86eb4f8b-5a5b-4b82-be22-45e48631cfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_orig: torch.Size([3, 81, 480, 832]) d_comfy: torch.Size([81, 480, 832])\n",
      "Using codec: 1983148141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@146.256] global cap_ffmpeg_impl.hpp:3207 open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0@146.256] global cap_ffmpeg_impl.hpp:3285 open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n",
      "OpenCV: FFMPEG: tag 0x34363248/'H264' is not supported with codec id 27 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x31637661/'avc1'\n",
      "[ERROR:0@146.256] global cap_ffmpeg_impl.hpp:3207 open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0@146.256] global cap_ffmpeg_impl.hpp:3285 open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved with H.264 codec to: orig.mp4\n",
      "Using codec: 1983148141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@146.794] global cap_ffmpeg_impl.hpp:3207 open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0@146.794] global cap_ffmpeg_impl.hpp:3285 open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n",
      "OpenCV: FFMPEG: tag 0x34363248/'H264' is not supported with codec id 27 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x31637661/'avc1'\n",
      "[ERROR:0@146.794] global cap_ffmpeg_impl.hpp:3207 open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0@146.794] global cap_ffmpeg_impl.hpp:3285 open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved with H.264 codec to: comfy.mp4\n",
      "Using codec: 1983148141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@147.379] global cap_ffmpeg_impl.hpp:3207 open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0@147.379] global cap_ffmpeg_impl.hpp:3285 open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n",
      "OpenCV: FFMPEG: tag 0x34363248/'H264' is not supported with codec id 27 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x31637661/'avc1'\n",
      "[ERROR:0@147.379] global cap_ffmpeg_impl.hpp:3207 open Could not find encoder for codec_id=27, error: Encoder not found\n",
      "[ERROR:0@147.379] global cap_ffmpeg_impl.hpp:3285 open VIDEOIO/FFMPEG: Failed to initialize VideoWriter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved with H.264 codec to: diff.mp4\n"
     ]
    }
   ],
   "source": [
    "print(\"d_orig:\", d_orig.shape, \"d_comfy:\", d_comfy[0].shape)\n",
    "\n",
    "# Convert decoded tensors to video\n",
    "# Split along dimension 1 to get individual frames\n",
    "frames_orig = torch.split(d_orig, 1, dim=1)\n",
    "frames_comfy = torch.split(d_comfy, 1, dim=1)\n",
    "frames_diff = torch.split((d_comfy - d_orig), 1, dim=1)\n",
    "\n",
    "# Save videos\n",
    "tensors_to_mp4_rgb(frames_orig, \"orig.mp4\", fps=16)\n",
    "tensors_to_mp4_rgb(frames_comfy, \"comfy.mp4\", fps=16)\n",
    "tensors_to_mp4_rgb(frames_diff, \"diff.mp4\", fps=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d81824-c01f-484f-80aa-2c9129ac7832",
   "metadata": {},
   "source": [
    "<video controls src=\"/ATI/wan_ati_standalone/diff.mp4\">animation</video>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff20269-555a-47bd-aa12-e8b4a0379711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48094647df0472bbaa2e1342c432897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Output(layout=Layout(grid_area='widget001')), Output(layout=Layout(grid_area='widget0…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Output, GridspecLayout\n",
    "from IPython import display\n",
    "\n",
    "filepaths = ['orig.mp4', 'comfy.mp4', 'diff.mp4']\n",
    "grid = GridspecLayout(1, len(filepaths))\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    out = Output()\n",
    "    with out:\n",
    "        display.display(display.Video(filepath, width=832//2, height=480//2, embed=True))\n",
    "    grid[0, i] = out\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "308609c9-9723-4928-a2a5-d3879b841c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tracks_orig = torch.load('tracks_pre_patch.pt')\n",
    "tracks_orig2 = torch.load('tracks_pre_process_out.pt')\n",
    "tracks_comfy = torch.load('/ComfyUI_fork/tracks.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8b7d0ae8-23e0-4773-a059-fa4b6726008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_diff = tracks_orig - tracks_comfy.to(tracks_orig.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c410d5e0-de79-427b-b200-b0db04520581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea3be911-8d6b-40fc-902d-9c72925f09fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([81, 4, 4])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_orig2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "985af598-6122-4ec5-96e0-59255dbf9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_p_orig = torch.load('tracks_pre_process.pt')\n",
    "tracks_p_comfy = torch.load('/ComfyUI_fork/tracks_pre_process.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a983215-7a0c-4dc8-b958-d58b85448c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = tracks_p_orig-tracks_p_comfy\n",
    "diff.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1eee317-6612-4745-a9d0-a97133e029c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tracks_p_orig.floor()-tracks_p_comfy).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "237a3aa0-daa7-4341-ae98-896684402108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43_cond.pt                   \u001b[0m\u001b[01;34mexamples\u001b[0m/\n",
      "43_cond_p5.pt                fix_cuda.py\n",
      "46_cond.pt                   orig.mp4\n",
      "README.md                    requirements.txt\n",
      "Untitled.ipynb               \u001b[01;32mrun_wan_ati.py\u001b[0m*\n",
      "check_arch_support.py        run_wan_ati_refactored.py\n",
      "check_checkpoint.py          test_chunked_load.py\n",
      "check_compute_capability.py  test_cuda_kernel.py\n",
      "check_gpu.sh                 test_fp8_minimal.py\n",
      "check_pytorch.py             test_fp8_ops.py\n",
      "comfy.mp4                    test_memory.py\n",
      "d1.mp4                       test_model_load.py\n",
      "d1_fixed.mp4                 test_motion_preprocessing.py\n",
      "d2.mp4                       tracks_pre_patch.pt\n",
      "debug_clip_checkpoint.py     tracks_pre_process.pt\n",
      "debug_cuda.py                vae_latent.pt\n",
      "diff.mp4                     validate_inputs.py\n",
      "diff_fixed.mp4               \u001b[01;34mwan\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b8957-1257-4d6d-87b0-0293d90e06e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
